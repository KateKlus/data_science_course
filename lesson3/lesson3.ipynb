{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Тема “Обучение с учителем в Scikit-learn”\n",
    "\n",
    "##### Задание 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "     y_test     y_pred\n",
      "173    23.6  28.648960\n",
      "274    32.4  36.495014\n",
      "491    13.6  15.411193\n",
      "72     22.8  25.403213\n",
      "452    16.1  18.855280\n",
      "76     20.0  23.146689\n",
      "316    17.8  17.392124\n",
      "140    14.0  14.078599\n",
      "471    19.6  23.036927\n",
      "500    16.8  20.599433\n",
      "0.7112260057484908\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "boston = load_boston()\n",
    "data = boston[\"data\"]\n",
    "feature_names = boston[\"feature_names\"]\n",
    "target = boston[\"target\"]\n",
    "X = pd.DataFrame(data, columns=feature_names)\n",
    "y = pd.DataFrame(target, columns=[\"price\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "check_test = pd.DataFrame({\n",
    "    \"y_test\": y_test[\"price\"],\n",
    "    \"y_pred\": y_pred.flatten()\n",
    "})\n",
    "\n",
    "print(check_test.head(10))\n",
    "\n",
    "r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Задание 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0.87472606157312\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model = RandomForestRegressor(max_depth=12, n_estimators=1000, random_state=42)\n",
    "model.fit(X_train, y_train.values[:, 0])\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "r2 = sklearn.metrics.r2_score(y_test, y_pred)\n",
    "print(r2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вывод - модель на основе деревьев работает точнее\n",
    "\n",
    "\n",
    "##### Задание 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Help on property:\n",
      "\n",
      "    The impurity-based feature importances.\n",
      "    \n",
      "    The higher, the more important the feature.\n",
      "    The importance of a feature is computed as the (normalized)\n",
      "    total reduction of the criterion brought by that feature.  It is also\n",
      "    known as the Gini importance.\n",
      "    \n",
      "    Warning: impurity-based feature importances can be misleading for\n",
      "    high cardinality features (many unique values). See\n",
      "    :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    feature_importances_ : ndarray of shape (n_features,)\n",
      "        The values of this array sum to 1, unless all trees are single node\n",
      "        trees consisting of only the root node, in which case it will be an\n",
      "        array of zeros.\n",
      "\n",
      "Summ of features: 1.0\n",
      "The most important features: ('LSTAT', 0.4158473181914483), ('RM', 0.4026817857034993)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "help(RandomForestRegressor.feature_importances_)\n",
    "importances = model.feature_importances_\n",
    "print(\"Sum of features: \" + str(sum(importances)))\n",
    "\n",
    "feats = {}\n",
    "for feature, importance in zip(feature_names, model.feature_importances_):\n",
    "    feats[feature] = importance\n",
    "\n",
    "sorted_tuples = sorted(feats.items(), key=lambda item: item[1], reverse=True)\n",
    "print(f\"The most important features: {sorted_tuples[0]}, {sorted_tuples[1]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}